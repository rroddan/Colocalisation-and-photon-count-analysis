{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(tracks) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes signed and dated by KD are debugging, any unsigned notes are from the BVH lab as part of the orignal \n",
    "#script -KD 2023.08.03\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import lumicks.pylake as lk\n",
    "import itertools\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "# We use skimage to downsample the data\n",
    "from skimage.measure import block_reduce\n",
    "from statistics import mean\n",
    "from statistics import median\n",
    "from scipy.stats import sem\n",
    "from matplotlib_venn import venn2 #this track is used for making venn diagrams of interactions\n",
    "#if you get an error here just add in the terminal from the python environment: pip intall matplotlib-venn\n",
    "%matplotlib inline\n",
    "# Use notebook if you're in Jupyter Notebook\n",
    "%matplotlib widget\n",
    "\n",
    "filename = glob.glob('*.h5') #fetches filename assuming only one .h5 in notebook\n",
    "if len(filename) == 1:\n",
    "    print (filename[0])\n",
    "else: \n",
    "    print (\"too many or too few .h5 files\")\n",
    "    print(len(filename))\n",
    "    \n",
    "#adjusted original command in track 1 of this cell from filename = glob.glob('*.h5') to filename = glob.glob('**/*.h5')\n",
    "#so glob.glob can find the h5 files in subdirectory -KD 2023.08.03\n",
    "\n",
    "#adjusted this back temporarily but is a good trick! -- MS 2023-08-16\n",
    "\n",
    "plt.close('all')#This closes any plots left open to save memory and loads up the .h5 file in folder\n",
    "file = lk.File(str(filename[0]))\n",
    "print(lk.File(str(filename[0])))\n",
    "list(file.kymos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "forcex = file[\"Force HF\"][\"Force 1x\"] #this cell downsamples the force to save memory and make it easier to visualize\n",
    "\n",
    "# time traces (seconds)\n",
    "time = forcex.timestamps/1e9\n",
    "time = time - time[0]\n",
    "sample_rate = forcex.sample_rate\n",
    "\n",
    "downsampled_rate = 50 # Hz, this rate can be changed as needed\n",
    "\n",
    "# downsample the force, nanostage position and time\n",
    "forcex_downsamp = forcex.downsampled_by(int(sample_rate/downsampled_rate))\n",
    "time_downsamp = forcex_downsamp.timestamps/1e9\n",
    "time_downsamp = time_downsamp - time_downsamp[0]\n",
    "\n",
    "median_force = (median(forcex_downsamp.data))\n",
    "kymowidget = lk.KymoWidgetGreedy\n",
    "#added here to try bypassing the above error from pylake wiki guessing probably an\n",
    "#effect of depreciations -KD 2023.08.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(file.kymos)\n",
    "\n",
    "#added for debugging below KD 2023.08.03\n",
    "\n",
    "kymosname = [x for x in file.kymos.keys()]\n",
    "\n",
    "#added with Sawyer's help where kymosname should be an object that matches list(file.kymos) as output from above\n",
    "#but is a hashable type, prevents error I was getting in the next cell where kymosname has been placed -KD 2023.08.04\n",
    "\n",
    "_, kymo = file.kymos.popitem() #after defining the downsample rate earlier, this actually does the downsampling\n",
    "\n",
    "data = file.kymos[kymosname[0]].get_image(channel=\"red\")\n",
    "\n",
    "#note this depends on the collection channel -- for Cy3 we use green -og comment on script\n",
    "#adjusted value from file.kymos[\"11\"] to value recognized, see cell above to use for debugging -KD 2023.08.04\n",
    "\n",
    "downsample_factor = 1\n",
    "data = block_reduce(data, (1, downsample_factor))\n",
    "#rgb = kymo.rgb_image\n",
    "kymo = file.kymos[kymosname[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a color adjustment so we can see the data better. this will preview the dataset in all three channels and also show the force.\n",
    "adjustment = lk.ColorAdjustment(0, 0.1)\n",
    "\n",
    "\n",
    "name, kymo = file.kymos.popitem()\n",
    "\n",
    "kymo.plot_with_force(\"1x\", \"rgb\", adjustment=adjustment, aspect_ratio=0.5)\n",
    "plt.show()\n",
    "\n",
    "pixel_size = kymo.pixelsize_um\n",
    "pixel_size_int = pixel_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lk.KymoWidgetGreedy(kymo, 'rgb', aspect='auto', adjustment=adjustment,  min_length=4, pixel_threshold=5, window=7, sigma=1, vmax=2)\n",
    "plt.show()\n",
    "#this first plot is to look at the kymograph on the pixel scale in order to decide if an upper and lower bound need to be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_top = 4.79\n",
    "crop_bottom = 20.16\n",
    "#renamed these variables so that things run smoothly downstream -- MAS 9-6-23\n",
    "adjusted_lower_bound = crop_top\n",
    "adjusted_upper_bound = crop_bottom\n",
    "steps_between_bounds = int((adjusted_upper_bound - adjusted_lower_bound) * 10) #defines number of 100 nm steps between bounds\n",
    "downsample_factor = 1\n",
    "\n",
    "kymo_crop = file.kymos[kymosname[0]].crop_by_distance(crop_top, crop_bottom)\n",
    "\n",
    "#viewing the kymographs this way will show them after they are cropped\n",
    "lk.KymoWidgetGreedy(kymo_crop, 'rgb', aspect='auto', adjustment=adjustment,  min_length=4, pixel_threshold=2, window=7, sigma=1, vmax=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This cell for tracking tracks with kymowidget greedy. It opens two views -- one with a fixed aspect ratio and one adjustable\n",
    "#By saving and loading the tracks as redkymotracks.txt, they can easily be swapped back and forth between views as needed. Also used a scaling color map. MAS 9-6-23\n",
    "red_tracks = lk.KymoWidgetGreedy(kymo_crop.downsampled_by(4), \"red\", aspect=\"auto\", min_length=4, pixel_threshold=1, window=12, sigma=0.25, vmax=25, correct_origin=True, cmap='viridis')\n",
    "\n",
    "#I prefer the auto aspect so I just commented this one out for now.\n",
    "#kymowidget1 = lk.KymoWidgetGreedy(kymo_crop.downsampled_by(downsample_factor), \"red\", axis_aspect_ratio=2, min_length=4, pixel_threshold=1, window=7, sigma=0.25, vmax=2, correct_origin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NOTE: MUST HAVE KYMOTRACKS LOADED OR THIS WILL ERROR.\n",
    "#Used this to replace the tracks and save_tracks functions below that have since been replaced with the \n",
    "#KymoTrackGroup tracks. Printed values should match, if they do not the analysis between the two is not the same.\n",
    "#Be sure to load and save between the widgets, but ultimately kymowidget1, the 2nd one, is the one that I've\n",
    "#chosen to export the .csv output required for further steps. The comma delimiter for the .csv is highly\n",
    "#recommended as comma delimited .csv files can be opened with Excel -KD 2023.08.07\n",
    "\n",
    "\n",
    "red_tracks.save_tracks('red-ontarget_kymotracks.csv', delimiter = ',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell for tracking green tracks with kymowidget greedy. It opens two views -- one with a fixed aspect ratio and one adjustable\n",
    "#By saving and loading the tracks as redkymotracks.txt, they can easily be swapped back and forth between views as needed. Also used a scaling color map. MAS 9-6-23\n",
    "green_tracks = lk.KymoWidgetGreedy(kymo_crop.downsampled_by(4), \"green\", aspect=\"auto\", min_length=4, pixel_threshold=1, window=12, sigma=0.25, vmax=25, correct_origin=True, cmap='viridis')\n",
    "\n",
    "#I prefer the auto aspect so I just commented this one out for now.\n",
    "#kymowidget1 = lk.KymoWidgetGreedy(kymo_crop.downsampled_by(downsample_factor), \"red\", axis_aspect_ratio=2, min_length=4, pixel_threshold=1, window=7, sigma=0.25, vmax=2, correct_origin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_tracks.save_tracks('green-ontarget_kymotracks.txt', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Replaced the above two obsolete cells with these commands containing updated, non-depreciated\n",
    "#parameters -KD 2023.08.07\n",
    "\n",
    "#Displays number of tracks tracked and number of theoretical bins that should be used. -MAS 2024.02.27\n",
    "numberofredtracks=len(red_tracks.tracks)\n",
    "numberofgreentracks=len(green_tracks.tracks)\n",
    "print(numberofredtracks)\n",
    "print(numberofgreentracks)\n",
    "numberofredbins = int(round(np.sqrt (numberofredtracks)) )\n",
    "print (numberofredbins)\n",
    "numberofgreenbins = int(round(np.sqrt (numberofgreentracks)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_track_idx = np.argmax([len(track) for track in red_tracks.tracks])  # Get the index of the longest track\n",
    "longest_track = red_tracks.tracks[longest_track_idx]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(longest_track.seconds, longest_track.position)\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Position [$\\mu$m]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#red trackS SECTION--------------------------------------------------------------\n",
    "redlengths = (track.time_idx[-1]-track.time_idx[0] for track in red_tracks.tracks)\n",
    "# Get the index of the longest kymo track\n",
    "redlongest_index = np.argmax(redlengths)\n",
    "\n",
    "# Select the longest red track\n",
    "redlongest_track = red_tracks.tracks[redlongest_index]\n",
    "dt = kymo.line_time_seconds\n",
    "redtimes = np.array([(track.time_idx[-1]-track.time_idx[0]) for track in red_tracks.tracks])*dt*downsample_factor\n",
    "\n",
    "#this section plots the positions of the longest track and also shows the raw image of that track \n",
    "#also leaves 1 second empty on each side so the start and end can be seen.\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(np.array(redlongest_track.time_idx) * dt, np.array(redlongest_track.coordinate_idx ) * dt, color = 'red') \n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Position [$\\mu$m]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "kymo.plot('rgb', aspect=\"auto\", adjustment=adjustment)\n",
    "plt.xlim([(np.array(redlongest_track.time_idx[0])) * dt -1, (np.array(redlongest_track.time_idx[-1])*dt +1 )])\n",
    "plt.ylim(adjusted_upper_bound+1, adjusted_lower_bound-1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "# Create a list to store track indices and average photon counts for all red tracks\n",
    "avg_counts_data = []\n",
    "figures = []\n",
    "\n",
    "downsample_factor = 1\n",
    "\n",
    "for i, track in enumerate(red_tracks.tracks):\n",
    "    # Get time and photon count data\n",
    "    time_vals = np.array(track.time_idx) * dt\n",
    "    photon_counts = track.sample_from_image(3)\n",
    "\n",
    "    # Apply downsampling\n",
    "    time_vals = time_vals[::downsample_factor]\n",
    "    photon_counts = photon_counts[::downsample_factor]\n",
    "\n",
    "    # Calculate line of best fit\n",
    "    coeffs = np.polyfit(time_vals, photon_counts, 1)  # Linear fit (degree 1)\n",
    "    best_fit_line = np.poly1d(coeffs)\n",
    "\n",
    "    # Calculate the average y-value\n",
    "    avg_y = np.mean(photon_counts)\n",
    "    \n",
    "    # Store the data for saving in \"index, value\" format\n",
    "    avg_counts_data.append(f\"{i}, {avg_y:.2f}\")\n",
    "\n",
    "    # Create figure for each plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.plot(time_vals, photon_counts, label=f'Track {i}', color='red')\n",
    "    ax.plot(time_vals, best_fit_line(time_vals), '--', color='black', label='Best Fit')\n",
    "    ax.set_ylabel('Photon count')\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_title(f'Photon count for Track {i}\\n(Average: {avg_y:.2f})')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Store figure in list\n",
    "    figures.append(fig)\n",
    "    \n",
    "    # Print the average photon count value\n",
    "    print(f'Track {i}: Average photon count = {avg_y:.2f}')\n",
    "\n",
    "    # Close the individual figure after saving\n",
    "    plt.close(fig)  # Close individual figure to free up memory\n",
    "\n",
    "# Save the average photon counts to a text file\n",
    "with open(\"average_red_photon_counts.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(avg_counts_data))\n",
    "\n",
    "print(\"Average photon counts saved to average_red_photon_counts.txt\")\n",
    "\n",
    "# Save all figures in a single image file\n",
    "num_plots = len(figures)\n",
    "cols = 4  # Number of columns in the grid\n",
    "rows = (num_plots + cols - 1) // cols  # Compute rows dynamically\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))\n",
    "axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "for ax in axes[len(figures):]:\n",
    "    ax.axis('off')  # Turn off unused subplots\n",
    "\n",
    "# Create the large figure with all the subplots and save it\n",
    "for i, fig in enumerate(figures):\n",
    "    fig.canvas.draw()\n",
    "    img_array = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    axes[i].imshow(img_array)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Track {i}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_red_photon_counts.png\", dpi=300)\n",
    "\n",
    "# Close the main figure that contains all subplots\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"All plots saved to all_red_photon_counts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trialling out segmenting the data to fit a line of best fit at different intervals \n",
    "\n",
    "# Create a list to store track indices and segment-wise averages\n",
    "avg_counts_data = []\n",
    "figures = []\n",
    "\n",
    "downsample_factor = 1  # Adjust downsampling if needed\n",
    "segment_duration = 20  # Fit a new line every 20 seconds\n",
    "\n",
    "for i, track in enumerate(red_tracks.tracks):\n",
    "    # Get time and photon count data\n",
    "    time_vals = np.array(track.time_idx) * dt\n",
    "    photon_counts = np.array(track.sample_from_image(3, correct_origin=True))  # Fix warning\n",
    "\n",
    "    # Apply downsampling\n",
    "    time_vals = time_vals[::downsample_factor]\n",
    "    photon_counts = photon_counts[::downsample_factor]\n",
    "\n",
    "    # Ensure they are NumPy arrays\n",
    "    time_vals = np.array(time_vals)\n",
    "    photon_counts = np.array(photon_counts)\n",
    "\n",
    "    # Determine time bins for segmentation\n",
    "    start_time = time_vals[0]\n",
    "    end_time = time_vals[-1]\n",
    "    time_bins = np.arange(start_time, end_time, segment_duration)\n",
    "\n",
    "    segment_averages = []\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.plot(time_vals, photon_counts, '-', color='red', label=f'Track {i}')  # Full kymotrack\n",
    "\n",
    "    # Iterate over each time segment\n",
    "    for j in range(len(time_bins) - 1):\n",
    "        # Select points within the current time window\n",
    "        mask = (time_vals >= time_bins[j]) & (time_vals < time_bins[j + 1])\n",
    "        segment_time = time_vals[mask]\n",
    "        segment_counts = photon_counts[mask]  # âœ… Fix boolean indexing issue\n",
    "\n",
    "        if len(segment_time) > 1:  # Ensure enough data points exist\n",
    "            # Fit a line for the segment\n",
    "            coeffs = np.polyfit(segment_time, segment_counts, 1)\n",
    "            best_fit_line = np.poly1d(coeffs)\n",
    "\n",
    "            # Compute segment average\n",
    "            avg_y = np.mean(segment_counts)\n",
    "            segment_averages.append(f\"{i}, {time_bins[j]:.1f}-{time_bins[j+1]:.1f}, {avg_y:.2f}\")\n",
    "\n",
    "            # Plot best-fit line for this segment\n",
    "            ax.plot(segment_time, best_fit_line(segment_time), '--', label=f'Fit {j}')\n",
    "\n",
    "    # Store segment-wise averages\n",
    "    avg_counts_data.extend(segment_averages)\n",
    "\n",
    "    # Finalize figure\n",
    "    ax.set_ylabel('Photon count')\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_title(f'Photon count for Track {i}')\n",
    "    ax.set_ylim(0, max(photon_counts) * 1.1)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Store figure in list\n",
    "    figures.append(fig)\n",
    "\n",
    "    # Close figure to free memory\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save segment-wise average photon counts to a text file\n",
    "with open(\"segment_average_red_photon_counts.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(avg_counts_data))\n",
    "\n",
    "print(\"Segment-wise average photon counts saved to segment_average_red_photon_counts.txt\")\n",
    "\n",
    "# Save all figures in a single image file\n",
    "num_plots = len(figures)\n",
    "cols = 4\n",
    "rows = (num_plots + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))\n",
    "axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "for ax in axes[len(figures):]:\n",
    "    ax.axis('off')  # Hide unused subplots\n",
    "\n",
    "for i, fig in enumerate(figures):\n",
    "    fig.canvas.draw()\n",
    "    img_array = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    axes[i].imshow(img_array)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Track {i}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_segmented_red_photon_counts.png\", dpi=300)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"All segmented plots saved to all_segmented_red_photon_counts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL FOR PROCESSING red CHANNEL DATA\n",
    "#to plot photon count along the longest track\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot( np.array(redlongest_track.time_idx) * dt, redlongest_track.sample_from_image(3), color='red') #this samples 3 pixels away from track position\n",
    "plt.ylabel('Photon count')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.title('Photon counts along the longest track')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plots track length as a histogram. numberofbins was defined earlier as square root of n\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(redtimes, numberofredbins, color='red')\n",
    "plt.ylabel('Events')\n",
    "plt.xlabel('Duration (s)')\n",
    "plt.title('Lengths of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plots track length as a histogram. numberofbins was defined earlier as square root of n\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(redtimes, numberofredbins, color='red')\n",
    "plt.ylabel('Events')\n",
    "plt.xlabel('Duration (s)')\n",
    "plt.title('Lengths of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of starting positions for each track\n",
    "redtime = [(track.time_idx[0]) * dt for track in red_tracks.tracks]\n",
    "##np.array(longest_track.coordinate_idx) * pixel_size / 1000\n",
    "startpositions = np.array([track.coordinate_idx[0] for track in red_tracks.tracks]) * pixel_size \n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(startpositions, steps_between_bounds, color='red') #Arbitrarily defined a bunch of bins on this, roughly corresponding to 100 nm. This can be altegreen.\n",
    "plt.xlabel('Start Position (um from top)')\n",
    "plt.ylabel('Number of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of mean positions for each track\n",
    "redmeanpositions = np.array([np.average(track.coordinate_idx) for track in red_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(redmeanpositions, steps_between_bounds, color='red')\n",
    "plt.xlabel('Average position (um from top)')\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#histogram of localization precision in um\n",
    "redstandarddeviation = np.array([np.std(track.coordinate_idx, ddof=1) for track in red_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(redstandarddeviation, numberofredbins, color='red')\n",
    "plt.xlabel('Localization precision (um)')\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#this saves the MSD vlues as a .txt file in case we want to graph these in excel/prism. Still under development.\n",
    "np.savetxt(\"std.txt\", \n",
    "           redstandarddeviation,\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "\n",
    "#histogram of normalized track positions in terms of percentage along DNA bound. \n",
    "#To function properly, upper and lower bound must be defined as the edge of the beads.\n",
    "#Any inaccuracies in calling the edge of the beads will also create inaccuracy in this measurement.\n",
    "rednorm_meanpositions = np.array([np.average(track.coordinate_idx) for track in red_tracks.tracks]) * pixel_size /(adjusted_upper_bound-adjusted_lower_bound)*100\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(rednorm_meanpositions, steps_between_bounds, color='red')\n",
    "plt.xlabel('Normalized average position (percent from top)')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#histogram of the difference between the start and endpoint of each track\n",
    "reddistancetraveled = np.array([track.coordinate_idx[-1]-track.coordinate_idx[0] for track in red_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(reddistancetraveled, numberofredbins, color='red')\n",
    "plt.ylabel('Event number')\n",
    "plt.xlabel('Distance traveled (um)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of the absolute value of the difference between the start and endpoint of each track\n",
    "redabsdistancetraveled = np.array([abs(track.coordinate_idx[-1]-track.coordinate_idx[0]) for track in red_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(redabsdistancetraveled, 11, color='red')\n",
    "plt.xlabel('Absolute value of distance traveled (um)')\n",
    "plt.ylabel('Number of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#green trackS SECTION--------------------------------------------------------------\n",
    "greenlengths = (track.time_idx[-1]-track.time_idx[0] for track in green_tracks.tracks)\n",
    "# Get the index of the longest kymo track\n",
    "greenlongest_index = np.argmax(greenlengths)\n",
    "\n",
    "# Select the longest green track\n",
    "greenlongest_track = green_tracks.tracks[greenlongest_index]\n",
    "dt = kymo.line_time_seconds\n",
    "greentimes = np.array([(track.time_idx[-1]-track.time_idx[0]) for track in green_tracks.tracks])*dt*downsample_factor\n",
    "\n",
    "#this section plots the positions of the longest track and also shows the raw image of that track \n",
    "#also leaves 1 second empty on each side so the start and end can be seen.\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.plot(np.array(greenlongest_track.time_idx) * dt, np.array(greenlongest_track.coordinate_idx ) * dt, color = 'green') \n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Position [$\\mu$m]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "kymo.plot('rgb', aspect=\"auto\", adjustment=adjustment)\n",
    "plt.xlim([(np.array(greenlongest_track.time_idx[0])) * dt -1, (np.array(greenlongest_track.time_idx[-1])*dt +1 )])\n",
    "plt.ylim(adjusted_upper_bound+1, adjusted_lower_bound-1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CELL FOR PROCESSING green CHANNEL DATA\n",
    "#to plot photon count along the longest track\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot( np.array(greenlongest_track.time_idx) * dt, greenlongest_track.sample_from_image(3), color='green') #this samples 3 pixels away from track position\n",
    "plt.ylabel('Photon count')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.title('Photon counts along the longest track')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#plots track length as a histogram. numberofbins was defined earlier as square root of n\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greentimes, numberofgreenbins, color='green')\n",
    "plt.ylabel('Events')\n",
    "plt.xlabel('Duration (s)')\n",
    "plt.title('Lengths of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#plots track length as a histogram. numberofbins was defined earlier as square root of n\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greentimes, numberofgreenbins, color='green')\n",
    "plt.ylabel('Events')\n",
    "plt.xlabel('Duration (s)')\n",
    "plt.title('Lengths of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of starting positions for each track\n",
    "greentime = [(track.time_idx[0]) * dt for track in green_tracks.tracks]\n",
    "##np.array(longest_track.coordinate_idx) * pixel_size / 1000\n",
    "startpositions = np.array([track.coordinate_idx[0] for track in green_tracks.tracks]) * pixel_size \n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(startpositions, steps_between_bounds, color='green') #Arbitrarily defined a bunch of bins on this, roughly corresponding to 100 nm. This can be altegreen.\n",
    "plt.xlabel('Start Position (um from top)')\n",
    "plt.ylabel('Number of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of mean positions for each track\n",
    "greenmeanpositions = np.array([np.average(track.coordinate_idx) for track in green_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greenmeanpositions, steps_between_bounds, color='green')\n",
    "plt.xlabel('Average position (um from top)')\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#histogram of localization precision in um\n",
    "greenstandarddeviation = np.array([np.std(track.coordinate_idx, ddof=1) for track in green_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greenstandarddeviation, numberofgreenbins, color='green')\n",
    "plt.xlabel('Localization precision (um)')\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#this saves the MSD vlues as a .txt file in case we want to graph these in excel/prism. Still under development.\n",
    "np.savetxt(\"std.txt\", \n",
    "           greenstandarddeviation,\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "\n",
    "#histogram of normalized track positions in terms of percentage along DNA bound. \n",
    "#To function properly, upper and lower bound must be defined as the edge of the beads.\n",
    "#Any inaccuracies in calling the edge of the beads will also create inaccuracy in this measurement.\n",
    "greennorm_meanpositions = np.array([np.average(track.coordinate_idx) for track in green_tracks.tracks]) * pixel_size /(adjusted_upper_bound-adjusted_lower_bound)*100\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greennorm_meanpositions, steps_between_bounds, color='green')\n",
    "plt.xlabel('Normalized average position (percent from top)')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylabel('Times occuring')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#histogram of the difference between the start and endpoint of each track\n",
    "greendistancetraveled = np.array([track.coordinate_idx[-1]-track.coordinate_idx[0] for track in green_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greendistancetraveled, numberofgreenbins, color='green')\n",
    "plt.ylabel('Event number')\n",
    "plt.xlabel('Distance traveled (um)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#histogram of the absolute value of the difference between the start and endpoint of each track\n",
    "greenabsdistancetraveled = np.array([abs(track.coordinate_idx[-1]-track.coordinate_idx[0]) for track in green_tracks.tracks]) * pixel_size\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(greenabsdistancetraveled, 11, color='green')\n",
    "plt.xlabel('Absolute value of distance traveled (um)')\n",
    "plt.ylabel('Number of events')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots the photon count for all green tracks, makes a line of best fit and saves this to a txt file and also saves all the plots\n",
    "\n",
    "# Create a list to store track indices and average photon counts for all green tracks\n",
    "avg_counts_data = []\n",
    "figures = []\n",
    "\n",
    "for i, track in enumerate(green_tracks.tracks):\n",
    "    # Get time and photon count data\n",
    "    time_vals = np.array(track.time_idx) * dt\n",
    "    photon_counts = track.sample_from_image(3)\n",
    "\n",
    "    # Calculate line of best fit\n",
    "    coeffs = np.polyfit(time_vals, photon_counts, 1)  # Linear fit (degree 1)\n",
    "    best_fit_line = np.poly1d(coeffs)\n",
    "\n",
    "    # Calculate the average y-value\n",
    "    avg_y = np.mean(photon_counts)\n",
    "    \n",
    "    # Store the data for saving in \"index, value\" format\n",
    "    avg_counts_data.append(f\"{i}, {avg_y:.2f}\")\n",
    "\n",
    "    # Create figure for each plot\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    ax.plot(time_vals, photon_counts, label=f'Track {i}', color='green')\n",
    "    ax.plot(time_vals, best_fit_line(time_vals), '--', color='black', label='Best Fit')\n",
    "    ax.set_ylabel('Photon count')\n",
    "    ax.set_xlabel('Time [s]')\n",
    "    ax.set_title(f'Photon count for Track {i}\\n(Average: {avg_y:.2f})')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Store figure in list\n",
    "    figures.append(fig)\n",
    "    \n",
    "    # Print the average photon count value\n",
    "    print(f'Track {i}: Average photon count = {avg_y:.2f}')\n",
    "\n",
    "# Save the average photon counts to a text file\n",
    "with open(\"average_green_photon_counts.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(avg_counts_data))\n",
    "\n",
    "print(\"Average photon counts saved to average_green_photon_counts.txt\")\n",
    "\n",
    "# Save all figures in a single image file\n",
    "num_plots = len(figures)\n",
    "cols = 4  # Number of columns in the grid\n",
    "rows = (num_plots + cols - 1) // cols  # Compute rows dynamically\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))\n",
    "axes = axes.flatten() if num_plots > 1 else [axes]\n",
    "\n",
    "for ax in axes[len(figures):]:\n",
    "    ax.axis('off')  # Turn off unused subplots\n",
    "\n",
    "for i, fig in enumerate(figures):\n",
    "    fig.canvas.draw()\n",
    "    img_array = np.array(fig.canvas.renderer.buffer_rgba())\n",
    "    axes[i].imshow(img_array)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Track {i}')\n",
    "    plt.close(fig)  # Close individual figures after rendering\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"all_green_photon_counts.png\", dpi=300)\n",
    "\n",
    "# Close the main figure that contains all subplots\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"All plots saved to all_green_photon_counts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocalization analysis\n",
    "colocalization_count = 0\n",
    "interaction_tuple = []\n",
    "interaction_window = 2 #distance in pixels for an interaction to occur\n",
    "time_window = 6 #distance in frames for an interaction to occur\n",
    "#the following loop iterates over the length of each track, comparing every coordinate to the coordinate of all tracks of the other color\n",
    "#if a point between both is closer than the interaction window and occurs within the time window, the interacting tracks will\n",
    "#be appended to the interaction tuple as coordinates\n",
    "for l in range (0, numberofredtracks):\n",
    "    redtracklength = len((red_tracks.tracks[l].coordinate_idx))\n",
    "    for i in range (0, redtracklength):\n",
    "        for j in range (0, numberofgreentracks):\n",
    "            greentracklength = len((green_tracks.tracks[j].coordinate_idx))\n",
    "            for k in range (0, greentracklength):\n",
    "                if abs(green_tracks.tracks[j].coordinate_idx[k]-red_tracks.tracks[l].coordinate_idx[i]) <= interaction_window and abs(green_tracks.tracks[j].time_idx[k] - red_tracks.tracks[l].time_idx[i]) <= time_window: \n",
    "                \n",
    "                    colocalization_count = colocalization_count + 1\n",
    "                    if len(interaction_tuple) > 0:\n",
    "                        if j != interaction_tuple [len(interaction_tuple)-1][1]:\n",
    "                            interaction_tuple.append((l, j))\n",
    "\n",
    "                            break\n",
    "                        break\n",
    "                    else: interaction_tuple.append((l,j))\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colocalization analysis\n",
    "colocalization_count = 0\n",
    "green_interaction_tuple = []\n",
    "\n",
    "#the following loop iterates over the length of each track, comparing every coordinate to the coordinate of all tracks of the other color\n",
    "#if a point between both is closer than the interaction window and occurs within the time window, the interacting tracks will\n",
    "#be appended to the interaction tuple as coordinates\n",
    "for l in range (0, numberofgreentracks):\n",
    "    greentracklength = len((green_tracks.tracks[l].coordinate_idx))\n",
    "    for i in range (0, greentracklength):\n",
    "        for j in range (0, numberofredtracks):\n",
    "            redtracklength = len((red_tracks.tracks[j].coordinate_idx))\n",
    "            for k in range (0, redtracklength):\n",
    "                if abs(red_tracks.tracks[j].coordinate_idx[k]-green_tracks.tracks[l].coordinate_idx[i]) <= interaction_window and abs(red_tracks.tracks[j].time_idx[k] - green_tracks.tracks[l].time_idx[i]) <= time_window: \n",
    "                \n",
    "                    colocalization_count = colocalization_count + 1\n",
    "                    #print (l, j)\n",
    "                    if len(green_interaction_tuple) > 0:\n",
    "                        if j != green_interaction_tuple [len(green_interaction_tuple)-1][0]:\n",
    "                            green_interaction_tuple.append((j, l))\n",
    "\n",
    "                            break\n",
    "                        break\n",
    "                    else: green_interaction_tuple.append((j,l))\n",
    "                break\n",
    "\n",
    "            \n",
    "\n",
    "green_interaction_tuple.sort()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sub_cats = []\n",
    "for ind in green_interaction_tuple:\n",
    "    if ind not in interaction_tuple:\n",
    "        unique_sub_cats.append(ind)\n",
    "\n",
    "\n",
    "for i in range (0, len(unique_sub_cats)):\n",
    "    interaction_tuple.append(unique_sub_cats[i])\n",
    "\n",
    "print (interaction_tuple, \"are the interacting tracks in the format (red, green)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#this window is used for visualizing two interacting tracks. two coordinates from the interaction tuple can be plugged in below\n",
    "#and both the track position and primary data will be shown side-by-side\n",
    "plt.close('all')\n",
    "redtracknumber= 0\n",
    "greentracknumber = 0\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "kymo.plot(\"rgb\", vmax=1, aspect=\"auto\", adjustment=adjustment)\n",
    "ax1.set_xlim([(np.array(green_tracks.tracks[greentracknumber].time_idx[0])) * dt -1, (np.array(green_tracks.tracks[greentracknumber].time_idx[-1]) * dt +1 )])\n",
    "ax1.set_ylim(adjusted_upper_bound+1, adjusted_lower_bound-1) \n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2, sharex = ax1, sharey = ax1)\n",
    "plt.plot(np.array(green_tracks.tracks[greentracknumber].time_idx) * dt, np.array(green_tracks.tracks[greentracknumber].coordinate_idx) * pixel_size + adjusted_lower_bound , color = 'green' ) \n",
    "plt.plot(np.array(red_tracks.tracks[redtracknumber].time_idx) * dt, np.array(red_tracks.tracks[redtracknumber].coordinate_idx) * pixel_size + adjusted_lower_bound, color = 'red' ) \n",
    "ax2.set_ylim(adjusted_upper_bound+1, adjusted_lower_bound-1)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Position [$\\mu$m]')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "ax1 = plt.subplot(2, 1, 1)\n",
    "kymo.plot(\"red\", vmax=1, aspect=\"auto\")\n",
    "ax1.set_xlim([(np.array(red_tracks.tracks[redtracknumber].time_idx[0])) * dt -1, (np.array(red_tracks.tracks[redtracknumber].time_idx[-1]) * dt +1 )])\n",
    "ax1.set_ylim(adjusted_upper_bound+1, adjusted_lower_bound-1) \n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2, sharex = ax1, sharey = ax1)\n",
    "plt.plot(np.array(green_tracks.tracks[greentracknumber].time_idx) * dt, np.array(green_tracks.tracks[greentracknumber].coordinate_idx) * pixel_size + adjusted_lower_bound, color = 'green' ) \n",
    "plt.plot(np.array(red_tracks.tracks[redtracknumber].time_idx) * dt, np.array(red_tracks.tracks[redtracknumber].coordinate_idx) * pixel_size + adjusted_lower_bound, color = 'red' ) \n",
    "ax2.set_ylim(adjusted_upper_bound+1, adjusted_lower_bound-1)\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Position [$\\mu$m]')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interaction statistics\n",
    "total_interactions=len(interaction_tuple)\n",
    "print (len(interaction_tuple), 'total interactions')\n",
    "greeninteractions = 1 #there has to be at least one interaction to start with, to compare for unique interactions\n",
    "if len(interaction_tuple) >0: # this statement checks that there is indeed 1 or more interactions. If not it sets the count to 0\n",
    "    for i in range (0, len(interaction_tuple)-1):\n",
    "        if interaction_tuple[i][0] != interaction_tuple[i+1][0]:\n",
    "            greeninteractions = greeninteractions + 1\n",
    "else:\n",
    "    greeninteractions = 0\n",
    "\n",
    "redinteractions = 1 #same as above but for red tracks\n",
    "if len(interaction_tuple) >0:\n",
    "    for k in range (0, len(interaction_tuple)-1):\n",
    "        if interaction_tuple[k][1] != interaction_tuple[k+1][1]:\n",
    "            redinteractions = redinteractions + 1\n",
    "else:\n",
    "    redinteractions = 0\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further colocalization patterns -- of the colocalizations, how many start with green, how many start with red, how many together?\n",
    "plt.close('all')\n",
    "timing_window = 6 #allowed window for events to occur at the same time\n",
    "interaction_starts = [] #if red comes on first, this is 0, if they start together: 1, if green is first: 2\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    if ((red_tracks.tracks[interaction_tuple[i][0]].time_idx[0]-green_tracks.tracks[interaction_tuple[i][1]].time_idx[0]) > timing_window):\n",
    "        interaction_starts.append(2)\n",
    "    if (abs(red_tracks.tracks[interaction_tuple[i][0]].time_idx[0]-green_tracks.tracks[interaction_tuple[i][1]].time_idx[0]) <= timing_window):\n",
    "        interaction_starts.append(1)\n",
    "    if ((green_tracks.tracks[interaction_tuple[i][1]].time_idx[0]-red_tracks.tracks[interaction_tuple[i][0]].time_idx[0]) > timing_window):\n",
    "        interaction_starts.append(0)\n",
    "#these outputs can be printed out for a double check if desired\n",
    "#print (interaction_starts)\n",
    "#print ('From',len(interaction_starts), 'interactions')\n",
    "\n",
    "#further colocalization patterns -- of the colocalizations, how many end with green, how many end with red, how many together?\n",
    "\n",
    "timing_window = 6 #allowed window for events to occur at the same time\n",
    "interaction_ends = [] #if red leaves first, this is 0, if they leave together: 1, if green leaves first: 2\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    if ((red_tracks.tracks[interaction_tuple[i][0]].time_idx[-1]-green_tracks.tracks[interaction_tuple[i][1]].time_idx[-1]) > timing_window):\n",
    "        interaction_ends.append(2)\n",
    "    if (abs(red_tracks.tracks[interaction_tuple[i][0]].time_idx[-1]-green_tracks.tracks[interaction_tuple[i][1]].time_idx[-1]) <= timing_window):\n",
    "        interaction_ends.append(1)\n",
    "    if ((green_tracks.tracks[interaction_tuple[i][1]].time_idx[-1]-red_tracks.tracks[interaction_tuple[i][0]].time_idx[-1]) > timing_window):\n",
    "        interaction_ends.append(0)\n",
    "#these outputs can be printed out for a double check if desired\n",
    "#print (interaction_ends)\n",
    "#print ('From',len(interaction_ends), 'interactions')\n",
    "\n",
    "\n",
    "greenstart = interaction_starts.count(2)\n",
    "doublestart = interaction_starts.count(1)\n",
    "redstart = interaction_starts.count(0)\n",
    "\n",
    "\n",
    "greenend = interaction_ends.count(0)\n",
    "doubleend = interaction_ends.count(1)\n",
    "redend = interaction_ends.count(2)\n",
    "#print (redend)\n",
    "# this section quantifies these phenomena to make venn diagrams based on what color starts and what color ends\n",
    "# basically this is a rough way of displaying order of assembly and dissassembly\n",
    "venn2(subsets = (greenstart, redstart, doublestart), set_labels = ('csb', 'csb'), set_colors=('green', 'red'));\n",
    "plt.title(\"Colocalization starting color\")\n",
    "plt.show()\n",
    "#this section generates a table categorizing each ternary event into 1 of 9 possible categories\n",
    "# in other words, this is a more rigorous way of showing order of assembly and dissassembly\n",
    "#this list starts as 3 as category 1 and 2 represent binary events\n",
    "\n",
    "interaction_categories = []\n",
    "\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    if interaction_starts[i] == 0:\n",
    "        if interaction_ends[i] == 0:\n",
    "            interaction_categories.append(11)\n",
    "        if interaction_ends[i] == 1: \n",
    "            interaction_categories.append(10)\n",
    "        if interaction_ends[i] == 2: \n",
    "            interaction_categories.append(9)    \n",
    "    if interaction_starts[i] == 1:\n",
    "        if interaction_ends[i] == 0:\n",
    "            interaction_categories.append(8)\n",
    "        if interaction_ends[i] == 1: \n",
    "            interaction_categories.append(7)\n",
    "        if interaction_ends[i] == 2: \n",
    "            interaction_categories.append(6) \n",
    "    if interaction_starts[i] == 2:\n",
    "        if interaction_ends[i] == 0:\n",
    "            interaction_categories.append(5)\n",
    "        if interaction_ends[i] == 1: \n",
    "            interaction_categories.append(4)\n",
    "        if interaction_ends[i] == 2: \n",
    "            interaction_categories.append(3)\n",
    "            \n",
    "print (interaction_categories)\n",
    "#this prints out all of the categories as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "venn2(subsets = (greenend, redend, doubleend), set_labels = ('snm1a', 'csb'), set_colors=('green', 'red'));\n",
    "plt.title(\"Colocalization ending color\")\n",
    "plt.show()\n",
    "#what color ends a colocalization event, i.e. the last color on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colocalization lifetimes \n",
    "#determines how long interactions occur before one or both partners leaves\n",
    "# as is this does not account for movement and assumes 1 colocalization for each set of tracks\n",
    "\n",
    "red_green_colocalization_lifetimes = []\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    if interaction_starts[i] == 0: # this means that red came on first, so the start of the colocalization is the first green time\n",
    "        coloc_start = green_tracks.tracks[interaction_tuple[i][1]].time_idx[0]\n",
    "    if interaction_starts[i] == 1: # this means that both colors came on together. For now we'll just take the average start.\n",
    "        coloc_start = ((green_tracks.tracks[interaction_tuple[i][1]].time_idx[0] + red_tracks.tracks[interaction_tuple[i][0]].time_idx[0])/2)\n",
    "    if interaction_starts[i] == 2: # this means that green came on first, so the start of the colocalization is the first red time\n",
    "        coloc_start = red_tracks.tracks[interaction_tuple[i][0]].time_idx[0]\n",
    "    if interaction_ends[i] == 0: # this means that green left last, so the end of the colocalization is the last red timepoint\n",
    "        coloc_end = red_tracks.tracks[interaction_tuple[i][0]].time_idx[-1]\n",
    "    if interaction_ends[i] == 1: # this means that both colors left together. For now we'll just take the average end.\n",
    "        coloc_end = ((green_tracks.tracks[interaction_tuple[i][1]].time_idx[-1] + red_tracks.tracks[interaction_tuple[i][0]].time_idx[-1])/2)    \n",
    "    if interaction_ends[i] == 2: # this means that red left last, so the end of the colocalization is the last green timepoint\n",
    "        coloc_end = green_tracks.tracks[interaction_tuple[i][1]].time_idx[-1]\n",
    "        \n",
    "    red_green_colocalization_lifetimes.append((coloc_end-coloc_start) * dt*downsample_factor)\n",
    "    \n",
    "print (red_green_colocalization_lifetimes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load photon counts from the precomputed files\n",
    "def load_avg_photon_counts(filename):\n",
    "    avg_counts = {}\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            index, value = line.strip().split(\", \")\n",
    "            avg_counts[int(index)] = float(value)\n",
    "    return avg_counts\n",
    "\n",
    "# Load average photon counts for red and green tracks\n",
    "avg_red_counts = load_avg_photon_counts(\"average_red_photon_counts.txt\")\n",
    "avg_green_counts = load_avg_photon_counts(\"average_green_photon_counts.txt\")\n",
    "\n",
    "# Your colocalization analysis code to find interaction tuples\n",
    "colocalization_count = 0\n",
    "green_interaction_tuple = []\n",
    "\n",
    "# Colocalization analysis to find interacting red and green tracks\n",
    "for l in range(0, numberofgreentracks):\n",
    "    greentracklength = len(green_tracks.tracks[l].coordinate_idx)\n",
    "    for i in range(0, greentracklength):\n",
    "        for j in range(0, numberofredtracks):\n",
    "            redtracklength = len(red_tracks.tracks[j].coordinate_idx)\n",
    "            for k in range(0, redtracklength):\n",
    "                if abs(red_tracks.tracks[j].coordinate_idx[k] - green_tracks.tracks[l].coordinate_idx[i]) <= interaction_window and \\\n",
    "                        abs(red_tracks.tracks[j].time_idx[k] - green_tracks.tracks[l].time_idx[i]) <= time_window:\n",
    "                    colocalization_count += 1\n",
    "                    if len(green_interaction_tuple) > 0:\n",
    "                        if j != green_interaction_tuple[len(green_interaction_tuple) - 1][0]:\n",
    "                            green_interaction_tuple.append((j, l))\n",
    "                            break\n",
    "                        break\n",
    "                    else:\n",
    "                        green_interaction_tuple.append((j, l))\n",
    "                break\n",
    "\n",
    "green_interaction_tuple.sort()\n",
    "\n",
    "# Merge unique interactions into the interaction_tuple\n",
    "unique_sub_cats = []\n",
    "for ind in green_interaction_tuple:\n",
    "    if ind not in interaction_tuple:\n",
    "        unique_sub_cats.append(ind)\n",
    "\n",
    "for i in range(0, len(unique_sub_cats)):\n",
    "    interaction_tuple.append(unique_sub_cats[i])\n",
    "\n",
    "print(interaction_tuple, \"are the interacting tracks in the format (red, green)\")\n",
    "\n",
    "# Now calculate the start times for red and green tracks that are part of the interaction tuples\n",
    "\n",
    "# Initialize list to store the output data\n",
    "output_data = []\n",
    "\n",
    "# Update downsample_factor\n",
    "downsample_factor = 1\n",
    "\n",
    "# Iterate through each interaction tuple and calculate relevant times and values\n",
    "for red_idx, green_idx in interaction_tuple:\n",
    "    # Time indices (scaled to seconds)\n",
    "    red_time_indices = red_tracks.tracks[red_idx].time_idx\n",
    "    green_time_indices = green_tracks.tracks[green_idx].time_idx\n",
    "\n",
    "    red_start_time = red_time_indices[0] * dt * downsample_factor\n",
    "    red_end_time = red_time_indices[-1] * dt * downsample_factor\n",
    "    red_duration = red_end_time - red_start_time\n",
    "\n",
    "    green_start_time = green_time_indices[0] * dt * downsample_factor\n",
    "    green_end_time = green_time_indices[-1] * dt * downsample_factor\n",
    "    green_duration = green_end_time - green_start_time\n",
    "\n",
    "    # Calculate overlap time\n",
    "    overlap_start = max(red_start_time, green_start_time)\n",
    "    overlap_end = min(red_end_time, green_end_time)\n",
    "    overlap_time = max(0.0, overlap_end - overlap_start)  # Avoid negative\n",
    "\n",
    "    # Calculate delay time\n",
    "    delay_time = green_start_time - red_start_time\n",
    "\n",
    "    # Retrieve average photon counts\n",
    "    avg_red_photon_count = avg_red_counts.get(red_idx, \"N/A\")\n",
    "    avg_green_photon_count = avg_green_counts.get(green_idx, \"N/A\")\n",
    "\n",
    "    # Format and append output\n",
    "    output_data.append(\n",
    "        f\"{red_idx}, {green_idx}, \"\n",
    "        f\"{red_start_time:.2f}, {red_end_time:.2f}, {red_duration:.2f}, \"\n",
    "        f\"{green_start_time:.2f}, {green_end_time:.2f}, {green_duration:.2f}, \"\n",
    "        f\"{overlap_time:.2f}, {delay_time:.2f}, \"\n",
    "        f\"{avg_red_photon_count:.2f}, {avg_green_photon_count:.2f}\"\n",
    "    )\n",
    "\n",
    "# Save the results to a text file\n",
    "output_filename = \"red_green_track_analysis_with_overlap.txt\"\n",
    "with open(output_filename, \"w\") as file:\n",
    "    # Write headers\n",
    "    file.write(\"Red Track Index, Green Track Index, \"\n",
    "               \"Red Start Time (s), Red End Time (s), Red Duration (s), \"\n",
    "               \"Green Start Time (s), Green End Time (s), Green Duration (s), \"\n",
    "               \"Overlap Time (s), Delay Time (s), \"\n",
    "               \"Avg Red Photon Count, Avg Green Photon Count\\n\")\n",
    "\n",
    "    # Write data\n",
    "    file.write(\"\\n\".join(output_data))\n",
    "\n",
    "print(f\"Track analysis (start, end, duration, overlap, photons) saved to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Analysis of single-color events without colocalization only, will output at end with the lengths of all events that didn't colocalize\n",
    "        \n",
    "\n",
    "def Filter(list1, list2):  #define a function to filter out any tracks with interactions\n",
    "    return (list(set(list2) - set(list1)))\n",
    "\n",
    "green_extracted_list = []\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    green_extracted_list.append(interaction_tuple[i][0])\n",
    "    \n",
    "green_track_list = np.arange(0, numberofgreentracks, 1) #this generates a list of green tracks that did not colocalize\n",
    "solo_green_tracks = Filter(green_extracted_list, green_track_list)\n",
    "\n",
    "\n",
    "\n",
    "solo_green_times_from_red = []\n",
    "for k in range (0, len(solo_green_tracks)):\n",
    "    solo_green_times_from_red.append(greentimes[solo_green_tracks[k]-1])\n",
    "\n",
    "\n",
    "red_extracted_list = []\n",
    "for i in range (0, len(interaction_tuple)):\n",
    "    red_extracted_list.append(interaction_tuple[i][1])\n",
    "    \n",
    "red_track_list = np.arange(0, numberofredtracks, 1) #this generates a list of red tracks that did not colocalize\n",
    "solo_red_tracks = Filter(red_extracted_list, red_track_list)\n",
    "#filtered = (list(set(red_track_list) - set(red_extracted_list)))\n",
    "\n",
    "\n",
    "\n",
    "solo_red_times_from_green = []\n",
    "for k in range (0, len(solo_red_tracks)):\n",
    "    solo_red_times_from_green.append(redtimes[solo_red_tracks[k]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classic venn diagram showing how many red alone, how many green alone, and how many colocalizations\n",
    "#also lists unique interactions (i.e., how many tracks of a color contribute to the middle portion)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "venn2(subsets = (len(solo_red_tracks), len(solo_green_tracks), len(red_green_colocalization_lifetimes)), set_labels = ('CSB', 'SNM1A'), set_colors=('red', 'green'), alpha = 0.5) \n",
    "plt.show()\n",
    "print(len(greentimes)-len(solo_green_times_from_red),\"unique green interactions\")\n",
    "print(len(redtimes)-len(solo_red_times_from_green),\"unique red interactions\")\n",
    "print(len(greentimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs key parameters. Super useful for comparing multiple datasets.\n",
    "#print (filename[0])\n",
    "\n",
    "print (median_force)\n",
    "\n",
    "print (numberofgreentracks)\n",
    "print (np.floor(max(time)), \"s is the final timepoint\")\n",
    "print (dt)\n",
    "print (pixel_size[0])\n",
    "#print ('Localization precision is',np.average(standarddeviation)*1000, 'plus or minus', (sem(standarddeviation)*1000), 'nm, assuming no diffusion')\n",
    "\n",
    "#this section saves down key parameters as .txt files. Can be used with the three-color analysis\n",
    "np.savetxt(\"greennorm_meanpositions.txt\", \n",
    "           greennorm_meanpositions,\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"rednorm_meanpositions.txt\", \n",
    "           rednorm_meanpositions,\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"greentimes.txt\", \n",
    "           (np.sort (greentimes)),\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"redtimes.txt\", \n",
    "           (np.sort (redtimes)),\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"red_green_colocalization_lifetimes.txt\", \n",
    "           np.sort(red_green_colocalization_lifetimes),\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"solo_green_times_from_red.txt\", \n",
    "           (np.sort (solo_green_times_from_red)),\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "np.savetxt(\"solo_red_times_from_green.txt\", \n",
    "           (np.sort (solo_red_times_from_green)),\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "\n",
    "np.savetxt(\"red_green_interaction_tuple.txt\", \n",
    "           interaction_tuple,\n",
    "           delimiter =\", \",\n",
    "            fmt = \"%s\")\n",
    "\n",
    "xarray = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
    "yarray = np.array([len(solo_green_tracks), len(solo_red_tracks), interaction_categories.count(3), interaction_categories.count(4), interaction_categories.count(5), interaction_categories.count(6), interaction_categories.count(7), interaction_categories.count(8), interaction_categories.count(9), interaction_categories.count(10), interaction_categories.count(11)])\n",
    "\n",
    "data = np.column_stack([xarray, yarray])\n",
    "\n",
    "np.savetxt(\"categories_of_colocalization.txt\", data, fmt=['%d','%d'])\n",
    "\n",
    "#this section saves all of the .txt files to a new folder based on colors of analysis\n",
    "#this way, multiple analyses of the data will not erase each other.\n",
    "parent_dir = os.getcwd()\n",
    "directory = \"redandgreen_offtarget\"\n",
    "newpath = os.path.join(parent_dir, directory)\n",
    "os.mkdir(newpath)\n",
    "path = os.getcwd() \n",
    "\n",
    "inpath = path\n",
    "outpath = (newpath)\n",
    "file_names = os.listdir(parent_dir)\n",
    "os.chdir(inpath)\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    shutil.copy(inpath+'/'+file,outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a file with the average photon counts of the solo green or red timesLoad precomputed average photon counts\n",
    "def load_avg_photon_counts(filename):\n",
    "    avg_counts = {}\n",
    "    with open(filename, \"r\") as file:\n",
    "        for line in file:\n",
    "            index, value = line.strip().split(\", \")\n",
    "            avg_counts[int(index)] = float(value)\n",
    "    return avg_counts\n",
    "\n",
    "# Load the photon counts\n",
    "avg_red_counts = load_avg_photon_counts(\"average_red_photon_counts.txt\")\n",
    "avg_green_counts = load_avg_photon_counts(\"average_green_photon_counts.txt\")\n",
    "\n",
    "# Function to filter tracks that didn't colocalize\n",
    "def Filter(list1, list2):  \n",
    "    return list(set(list2) - set(list1))\n",
    "\n",
    "# Identify solo green tracks\n",
    "green_extracted_list = [interaction[0] for interaction in interaction_tuple]  # Extract green tracks in interactions\n",
    "green_track_list = np.arange(0, numberofgreentracks, 1)  # All green tracks\n",
    "solo_green_tracks = Filter(green_extracted_list, green_track_list)\n",
    "\n",
    "# Identify solo red tracks\n",
    "red_extracted_list = [interaction[1] for interaction in interaction_tuple]  # Extract red tracks in interactions\n",
    "red_track_list = np.arange(0, numberofredtracks, 1)  # All red tracks\n",
    "solo_red_tracks = Filter(red_extracted_list, red_track_list)\n",
    "\n",
    "# Store output data (Track Index, Avg Photon Count)\n",
    "green_output_data = [f\"{track}, {avg_green_counts.get(track, 'N/A'):.2f}\" for track in solo_green_tracks]\n",
    "red_output_data = [f\"{track}, {avg_red_counts.get(track, 'N/A'):.2f}\" for track in solo_red_tracks]\n",
    "\n",
    "# Save the results to text files\n",
    "with open(\"solo_green_photoncounts.txt\", \"w\") as file:\n",
    "    file.write(\"Track Index, Avg Photon Count\\n\")\n",
    "    file.write(\"\\n\".join(green_output_data))\n",
    "\n",
    "with open(\"solo_red_photoncounts.txt\", \"w\") as file:\n",
    "    file.write(\"Track Index, Avg Photon Count\\n\")\n",
    "    file.write(\"\\n\".join(red_output_data))\n",
    "\n",
    "print(\"Solo green photon count data saved to solo_green_photoncounts.txt\")\n",
    "print(\"Solo red photon count data saved to solo_red_photoncounts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, track in enumerate(red_tracks.tracks):\n",
    "    lags, msd_values = track.msd(max_lag=1000)\n",
    "    msd_data = np.column_stack((lags, msd_values))\n",
    "    \n",
    "    filename = f\"track{i}_msd.txt\"\n",
    "    np.savetxt(filename, \n",
    "               msd_data, \n",
    "               delimiter=\", \", \n",
    "               fmt=\"%.6f\", \n",
    "               header=\"Lag, MSD\", \n",
    "               comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, track in enumerate(green_tracks.tracks):\n",
    "    lags, msd_values = track.msd(max_lag=1000)\n",
    "    msd_data = np.column_stack((lags, msd_values))\n",
    "    \n",
    "    filename = f\"track{i}_msd_green.txt\"\n",
    "    np.savetxt(filename, \n",
    "               msd_data, \n",
    "               delimiter=\", \", \n",
    "               fmt=\"%.6f\", \n",
    "               header=\"Lag, MSD\", \n",
    "               comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
